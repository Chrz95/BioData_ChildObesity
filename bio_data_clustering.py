# -*- coding: utf-8 -*-
"""Bio_Data_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bI1KY4CBeKADyxbd_ypHtMk3gLPnjdz3

## Loading the data
"""

import numpy as np
import os
from sklearn.impute import SimpleImputer
import pandas as pd
import seaborn as sns
import re
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import VarianceThreshold
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import classification_report
from imblearn.pipeline import Pipeline
from sklearn.decomposition import PCA
from sklearn.model_selection import GridSearchCV
import time
import xgboost as xgb
import warnings 
warnings.filterwarnings('ignore')

lists_directories = [['data/pilot/fitbit','data/pilot/old/selfObservation','data/pilot/old/questionnaire']]

for cnt, lst in enumerate(lists_directories):
    fitbit_data_dir, self_obs_data_dir, questionnaire_data_dir = lst

    ext = ('.csv')

    # Read fitbit_data
    fitbit_data_lst = []
    groups = ['control', 'intervention']

    source = fitbit_data_dir

    for gr in groups:
        fitbit_data_dir = source + '/' + gr
        for files in os.listdir(fitbit_data_dir):
            if files.endswith(ext):
                ##print(fitbit_data_dir + "/" + files)
                fitbit_data = pd.read_csv(fitbit_data_dir + "/" + files, delimiter=',', dtype=object)
                fitbit_data['pid'] = files[0:-4]
                fitbit_data.rename(columns={'date': 'timestamp'}, inplace=True)
                fitbit_data_lst.append(fitbit_data)

    fitbit_data = pd.concat(fitbit_data_lst, axis=0, ignore_index=True)

    # fitbit_data - Keep only useful columns
    fitbit_data = fitbit_data[["pid", 'timestamp', "sleepAsleepMinutes", "distance", 'steps']]
    int_columns = ["sleepAsleepMinutes", "distance", 'steps']
    #fitbit_data.head()

    for i in int_columns:
        fitbit_data[i] = fitbit_data[i].astype(str).str.replace(',', '.')
        fitbit_data[i] = fitbit_data[i].astype(str).str.replace('<', '')
        fitbit_data[i] = fitbit_data[i].astype(str).str.replace('Ο', '0')
        fitbit_data[i] = fitbit_data[i].astype(str).str.replace(' ', '')
        fitbit_data[i] = fitbit_data[i].replace('nan', np.nan)
        fitbit_data[i] = fitbit_data[i].replace('-', np.nan)

    fitbit_data = fitbit_data.fillna(0)

    # Convert columns to their correct type
    fitbit_data['timestamp'] = pd.to_datetime(fitbit_data['timestamp']).dt.date
    fitbit_data['sleepAsleepMinutes'] = fitbit_data['sleepAsleepMinutes'].astype("int")
    fitbit_data['distance'] = fitbit_data['distance'].astype("int")
    fitbit_data['steps'] = fitbit_data['steps'].astype("int")

    #fitbit_data.head()

    # Group by
    fitbit_data = fitbit_data.groupby(by=["pid", "timestamp"], as_index=False, sort=False).sum()
    #fitbit_data.head()

    """### Fitbit adherence"""

    ##print(fitbit_data.columns)
    pids = list(fitbit_data["pid"].unique())

    for pid in pids:
        temp = fitbit_data.loc[fitbit_data['pid'] == pid]
        number_of_days = len(temp["timestamp"].unique())
        no_exercise_days_count = len(temp["steps"].loc[lambda x: x != 0])
        ##print(pid,no_exercise_days_count,number_of_days,str((no_exercise_days_count/number_of_days) * 100) + "%")

    ext = ('.csv')
    # Read self_obs_data
    self_obs_data_lst = []
    for files in os.listdir(self_obs_data_dir):
        if files.endswith(ext):
            # #print(files)
            self_obs_data = pd.read_csv(self_obs_data_dir + "/" + files, delimiter=';', dtype=object)
            self_obs_data['pid'] = files[0:-4]
            # #print(self_obs_data)
            self_obs_data_lst.append(self_obs_data)

    self_obs_data = pd.concat(self_obs_data_lst, axis=0, ignore_index=True)

    # Read questionaire data
    # Read self_obs_data
    questionnaire_data_lst = []
    file_names = []
    for files in os.listdir(questionnaire_data_dir):
        if files.endswith(ext):
            # #print(files)
            file_names.append(files)
            questionnaire_data = pd.read_csv(questionnaire_data_dir + "/" + files, delimiter=';', dtype=object)
            # #print(self_obs_data)
            questionnaire_data.columns = questionnaire_data.columns.str.replace("\n", " ")
            questionnaire_data_lst.append(questionnaire_data)

    for i in range(len(questionnaire_data_lst)):
        for col in questionnaire_data_lst[i].columns:
            if (('Score' not in col) and ('pid' != col)) or ('- t' in col):
                del questionnaire_data_lst[i][col]

    questionnaire_data = questionnaire_data_lst[0]
    for i in range(1, len(questionnaire_data_lst)):
        questionnaire_data = pd.merge(questionnaire_data, questionnaire_data_lst[i], how='outer', left_on=['pid'],
                                      right_on=['pid'])

    #questionnaire_data.info()

    """### Remove useless columns to allow join"""

    # #print sub-data
    ##print(fitbit_data.info())

    ##print(self_obs_data.info())

    ##print(questionnaire_data.info())

    # self_obs_data
    self_obs_data = self_obs_data[["pid", 'timestamp', 'target', "weight", "home", "junk"]]

    for i in ['target', "weight", "home", "junk"]:
        self_obs_data[i] = self_obs_data[i].astype(str).str.replace(',', '.')
        self_obs_data[i] = self_obs_data[i].astype(str).str.replace('<', '')
        self_obs_data[i] = self_obs_data[i].astype(str).str.replace('Ο', '0')
        self_obs_data[i] = self_obs_data[i].astype(str).str.replace(' ', '')
        self_obs_data[i] = self_obs_data[i].replace('nan', np.nan)
        self_obs_data[i] = self_obs_data[i].replace('-', np.nan)

    remap = {'Ναι': 1, 'Όχι': 0, ' ': np.nan}
    self_obs_data['target'] = self_obs_data['target'].map(remap)
    self_obs_data['home'] = self_obs_data["home"].map(remap)
    self_obs_data['junk'] = self_obs_data["junk"].map(remap)
    self_obs_data['timestamp'] = pd.to_datetime(self_obs_data['timestamp']).dt.date

    # self_obs_data.head()

    """### Self-observation adherence"""

    for pid in pids:
        temp = fitbit_data.loc[fitbit_data['pid'] == pid]
        number_of_days = len(temp["timestamp"].unique())

        temp_obs = self_obs_data.loc[self_obs_data['pid'] == pid]
        seb_obs_rec = len(temp_obs["pid"])

        # print(pid,seb_obs_rec,number_of_days,str((seb_obs_rec/number_of_days) * 100) + "%")

    """### Join them"""

    # Join data based on pid and timestamp
    temp_data = pd.merge(fitbit_data, self_obs_data, how='left', left_on=['pid', "timestamp"],
                         right_on=['pid', "timestamp"])
    del fitbit_data
    del self_obs_data
    # temp_data.head()

    # Remove lines that have steps = NAN
    temp_data = temp_data[temp_data['steps'].notna()]
    # Remove columns that are all empty
    temp_data = temp_data.dropna(axis=1, how='all')

    # Join data based on pid
    data = pd.merge(temp_data, questionnaire_data, how='left', left_on=['pid'], right_on=['pid'])
    del temp_data

    """# **Pre-processing**"""

    # obj = data.select_dtypes(include=[np.object])
    # for i in data.columns:
    # if "Score" in i:
    # print(i)

    # for name,col_type in zip(data.columns,data.dtypes):
    # print (name,col_type)

    """### Remove duplicates"""

    # print(data.shape)
    data = data.drop_duplicates()
    # print(data.shape)

    """## Convert column types

    ### Convert to Float
    """

    # fix score columns

    scores = ['Score_mother - v', 'Score_fp - v', 'Score_fp_post - v', 'Score_mother_post - v', 'Score_sd_post - v',
              'Score_sd - v']

    for i in scores:
        data[i] = data[i].astype(str)

    data[['Mother_Yp', 'Mother_Aus', 'Mother_Ep', 'Mother_Aut']] = data['Score_mother - v'].str.split(',', expand=True)
    data[['sd_Tot', 'sd_Emo', 'sd_Cond', 'sd_Hyper', 'sd_Peer', 'sd_Beh']] = data['Score_sd - v'].str.split(',',
                                                                                                            expand=True)
    data[['fp_Mon', 'fp_Con', 'fp_Reg', 'fp_Guid', 'fp_Res', 'fp_Press']] = data['Score_fp - v'].str.split(',',
                                                                                                           expand=True)
    data[['Post_Mother_Yp', 'Post_Mother_Aus', 'Post_Mother_Ep', 'Post_Mother_Aut']] = data[
        'Score_mother_post - v'].str.split(',', expand=True)
    data[['Post_sd_Tot', 'Post_sd_Emo', 'Post_sd_Cond', 'Post_sd_Hyper', 'Post_sd_Peer', 'Post_sd_Beh']] = data[
        'Score_sd_post - v'].str.split(',', expand=True)
    data[['Post_fp_Mon', 'Post_fp_Con', 'Post_fp_Reg', 'Post_fp_Guid', 'Post_fp_Res', 'Post_fp_Press']] = data[
        'Score_fp_post - v'].str.split(',', expand=True)

    sd = ['sd_Tot', 'sd_Emo', 'sd_Cond', 'sd_Hyper', 'sd_Peer', 'sd_Beh', 'Post_sd_Tot', 'Post_sd_Emo', 'Post_sd_Cond',
          'Post_sd_Hyper', 'Post_sd_Peer', 'Post_sd_Beh']

    data[['sd_Tot', '1']] = data['sd_Tot'].str.split(' ', expand=True)
    data[['sd_Emo', '2']] = data['sd_Emo'].str.split(' ', expand=True)
    data[['sd_Cond', '3']] = data['sd_Cond'].str.split(' ', expand=True)
    data[['sd_Hyper', '4']] = data['sd_Hyper'].str.split(' ', expand=True)
    data[['sd_Peer', '5']] = data['sd_Peer'].str.split(' ', expand=True)
    data[['sd_Beh', '6']] = data['sd_Beh'].str.split(' ', expand=True)
    data[['Post_sd_Tot', '7']] = data['Post_sd_Tot'].str.split(' ', expand=True)
    data[['Post_sd_Emo', '8']] = data['Post_sd_Emo'].str.split(' ', expand=True)
    data[['Post_sd_Cond', '9']] = data['Post_sd_Cond'].str.split(' ', expand=True)
    data[['Post_sd_Hyper', '10']] = data['Post_sd_Hyper'].str.split(' ', expand=True)
    data[['Post_sd_Peer', '11']] = data['Post_sd_Peer'].str.split(' ', expand=True)
    data[['Post_sd_Beh', '12']] = data['Post_sd_Beh'].str.split(' ', expand=True)

    data = data.drop(columns=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])
    data = data.drop(columns=['Score_mother - v', 'Score_fp - v', 'Score_fp_post - v', 'Score_mother_post - v', 'Score_sd_post - v',
                 'Score_sd - v'])

    # convert to float

    data_float = ['weight', 'BMI - v_x', 'βάρος γέννησης - v', 'μήκος σώματος - v', 'περίμετρος κεφαλής - v',
                  'ΒΑΡΟΣ ΜΗΤΕΡΑΣ ΠΡΟ ΚΥΗΣΗΣ - v', 'ΒΑΡΟΣ ΜΗΤΡΟΣ - v', 'ΥΨΟΣ ΜΗΤΡΟΣ - v', \
                  'ΒΑΡΟΣ ΠΑΤΡΟΣ - v', 'ΥΨΟΣ ΠΑΤΡΟΣ - v', 'BMI_Mother', 'BMI_Father',
                  'ΠΡΟΣΛΗΨΗ ΒΑΡΟΥΣ ΚΑΤΑ ΤΗΝ ΕΓΚΥΜΟΣΥΝΗ - v', 'HbA1c - v', 'Chol - v', 'HDL - v', 'LDL - v', \
                  'TG - v', 'Lp(a) - v', 'SGOT - v', 'SGPT - v', 'γGT - v', 'FSH - v', 'TSH - v', 'UA - v',
                  '25 (OH) vitamin D - v', 'FreeT4 - v', 'Κορτιζόλη - v', \
                  'Ινσουλίνη - v', 'Τεστοστερόνη - v', 'ACTH - v', 'LH - v', 'Οιστραδιόλη - v', 'Γλυκόζη - v',
                  'Ύψος σε μέτρα - v', 'Βάρος σε κιλά - v', \
                  'Score - v', 'Score_psycho - v', 'BMI_Mother', 'BMI_Father', 'Mother_Yp', 'Mother_Aus', 'Mother_Ep',
                  'Mother_Aut', \
                  'sd_Tot', 'sd_Emo', 'sd_Cond', 'sd_Hyper', 'sd_Peer', 'sd_Beh', 'fp_Mon', 'fp_Con', 'fp_Reg',
                  'fp_Guid', 'fp_Res', 'fp_Press', \
                  'Post_Mother_Yp', 'Post_Mother_Aus', 'Post_Mother_Ep', 'Post_Mother_Aut', 'Post_sd_Tot',
                  'Post_sd_Emo', 'Post_sd_Cond', 'Post_sd_Hyper', 'Post_sd_Peer', 'Post_sd_Beh', \
                  'Post_fp_Mon', 'Post_fp_Con', 'Post_fp_Reg', 'Post_fp_Guid', 'Post_fp_Res', 'Post_fp_Press']


    for i in data_float:
        try:
            data[i] = data[i].astype(str).str.replace(',', '.')
            data[i] = data[i].astype(str).str.replace('<', '')
            data[i] = data[i].astype(str).str.replace('Ο', '0')
            data[i] = data[i].astype(str).str.replace(' ', '')
            data[i] = data[i].astype(str).str.replace('-', 'nan')
            data[i] = data[i].astype(str).str.replace('None', 'nan')
            data[i] = data[i].replace('nan', np.nan)
        except:
            continue

    for col in data_float:
        try:
            data[col] = data[col].astype(float)
        except:
            continue

    """  ### Convert to String and Date"""

    # convert to string
    data["pid"] = data["pid"].astype(str)

    # convert to int

    data_int = ['target', 'home', 'junk', 'ΔΙΑΡΚΕΙΑ  θΗΛΑΣΜΟΥ ΣΕ ΜΗΝΕΣ - v',
                'ΔΙΑΡΚΕΙΑ ΑΠΟΚΛΕΙΣΤΙΚΟΥ ΘΗΛΑΣΜΟΥ (ΜΗΝΕΣ): - v', 'ΔΙΑΡΚΕΙΑ ΜΙΚΤΟΥ ΘΗΛΑΣΜΟΥ (ΜΗΝΕΣ): - v', 'Φύλο - v',
                'Ηλικία - v', \
                'Με βάση το ύψος σας και το σωματικό σας βάρος, θεωρείτε πως είστε - v',
                'Ποια είναι η οικογενειακή σας κατάσταση; - v', 'Ποια είναι η εθνικότητά σας*; - v', \
                'Ποιο είναι το μορφωτικό σας επίπεδο; - v',
                'Ποια είναι η εργασία σας; (σε περίπτωση συνταξιοδότησης σημειώνετε την απασχόληση πριν από τη συνταξιοδότηση) - v', \
                'Είστε ικανοποιημένος με το εισόδημά σας; - v',
                'Ποιο είναι το ακαθάριστο ετήσιο εισόδημά σας; (η ερώτηση αυτή είναι προαιρετική) - v',
                'Είστε καπνιστής; - v', \
                'Το οικογενειακό σας εισόδημα καλύπτει τις ανάγκες σας; - v', 'Ασκείστε; Πόσο συχνά; - v',
                'Καταναλώνετε αλκοολούχα ποτά; - v', \
                'Νοσείτε από κάποια χρόνια ασθένεια (πχ. Υπέρταση, Δυσλιπιδαιμία, Διαβήτη,); - v',
                'Πόσο καλή είναι η υγεία σας; - v']

    for i in data_int:
        try:
            data[i] = data[i].astype(str).str.replace(',', '.')
            data[i] = data[i].astype(str).str.replace('<', '')
            data[i] = data[i].astype(str).str.replace('Ο', '0')
            data[i] = data[i].astype(str).str.replace(' ', '')
            data[i] = data[i].astype(str).str.replace('-', 'nan')
            data[i] = data[i].replace('nan', np.NaN)
        except:
            continue

    for col in data_int:
        try:
            data[col] = pd.to_numeric(data[col])
            data[col] = data[col].astype(int, errors='ignore')
        except:
            continue

    ### Numerical
    """

    #columns that can be replaced by mean values
    data_mean = ['weight','sleepAsleepMinutes', 'Εβδομάδες κύησης - v', 'βάρος γέννησης - v', 'μήκος σώματος - v', 'περίμετρος κεφαλής - v', 'ΒΑΡΟΣ ΜΗΤΕΡΑΣ ΠΡΟ ΚΥΗΣΗΣ - v',\
                 'ΠΡΟΣΛΗΨΗ ΒΑΡΟΥΣ ΚΑΤΑ ΤΗΝ ΕΓΚΥΜΟΣΥΝΗ - v', 'ΔΙΑΡΚΕΙΑ  θΗΛΑΣΜΟΥ ΣΕ ΜΗΝΕΣ - v', 'ΔΙΑΡΚΕΙΑ ΑΠΟΚΛΕΙΣΤΙΚΟΥ ΘΗΛΑΣΜΟΥ (ΜΗΝΕΣ): - v', 'ΔΙΑΡΚΕΙΑ ΜΙΚΤΟΥ ΘΗΛΑΣΜΟΥ (ΜΗΝΕΣ): - v',\
                 'ΗΛΙΚΙΑ ΜΗΤΡΟΣ - v', 'ΒΑΡΟΣ ΜΗΤΡΟΣ - v', 'ΥΨΟΣ ΜΗΤΡΟΣ - v', 'ΗΛΙΚΙΑ ΠΑΤΡΟΣ - v', 'ΒΑΡΟΣ ΠΑΤΡΟΣ - v', 'ΥΨΟΣ ΠΑΤΡΟΣ - v', 'ΜΕΣΟΔΙΑΣΤΗΜΑΤΑ ΜΕΤΑΞΥ ΓΕΥΜΑΤΩΝ: - v',\
                 'ΑΡΙΘΜΟΣ ΜΙΚΡΟΓΕΥΜΑΤΩΝ / ΣΝΑΚ - v', 'ΟΙΚΟΓΕΝΕΙΑΚΑ ΓΕΥΜΑΤΑ - v', 'ΑΡΙΘΜΟΣ ΚΥΡΙΩΝ ΓΕΥΜΑΤΩΝ - v', 'Ηλικία - v', 'HbA1c - v', 'Chol - v', 'HDL - v', 'LDL - v',\
                 'TG - v', 'Lp(a) - v', 'SGOT - v', 'SGPT - v', 'γGT - v', 'FSH - v', 'TSH - v', 'UA - v', '25 (OH) vitamin D - v', 'FreeT4 - v', 'Κορτιζόλη - v', 'Ινσουλίνη - v',\
                 'Τεστοστερόνη - v', 'ACTH - v', 'LH - v', 'Οιστραδιόλη - v', 'Γλυκόζη - v', 'Ύψος σε μέτρα - v', 'Βάρος σε κιλά - v',\
                 'Score - v', 'Score_psycho - v', 'BMI_Mother', 'BMI_Father', 'Mother_Yp', 'Mother_Aus', 'Mother_Ep', 'Mother_Aut',\
                 'sd_Tot', 'sd_Emo', 'sd_Cond', 'sd_Hyper', 'sd_Peer', 'sd_Beh', 'fp_Mon', 'fp_Con', 'fp_Reg', 'fp_Guid', 'fp_Res', 'fp_Press',\
                 'Post_Mother_Yp', 'Post_Mother_Aus', 'Post_Mother_Ep', 'Post_Mother_Aut', 'Post_sd_Tot', 'Post_sd_Emo', 'Post_sd_Cond', 'Post_sd_Hyper', 'Post_sd_Peer', 'Post_sd_Beh',\
                 'Post_fp_Mon', 'Post_fp_Con', 'Post_fp_Reg', 'Post_fp_Guid', 'Post_fp_Res', 'Post_fp_Press']

    ##print columns and their missing values
    #for column in data.columns:
        #print(column,": ",data[column].isnull().sum())

    data.replace('nan',np.NaN,inplace=True)

    for col in data_mean:
      data[col].fillna(data[col].mean(), inplace=True)

    #print()
    #print()
    ##print columns and their missing values after removing them
    #for column in data.columns:
        #print(column,": ",data[column].isnull().sum())

    """  ### Categorical

    """

    # Map categorical values
    probmap = {'Υποθυρεοειδισμος κύησης': 1, 'Θρομβοφιλία': 1, 'Μερική αποκόλληση πλακούντα': 1, '-': 0}
    data['ΑΛΛΑ ΠΡΟΒΛΗΜΑΤΑ ΚΑΤΑ ΤΗΝ ΚΥΗΣΗ - v'] = data['ΑΛΛΑ ΠΡΟΒΛΗΜΑΤΑ ΚΑΤΑ ΤΗΝ ΚΥΗΣΗ - v'].map(probmap)

    nmmap = {'Προδιαβήτης': 1, 'Ιστορικό Ca μαστού': 1, '4,5,6': 1, '6': 1, 'Διπολική διαταραχή': 1, '0': 0}
    data['ΝΟΣΗΜΑΤΑ ΜΗΤΡΟΣ - v'] = data['ΝΟΣΗΜΑΤΑ ΜΗΤΡΟΣ - v'].map(nmmap)

    npmap = {'1,2': 1, '2': 1, '5': 1, '2,5': 1, 'Νευροεκφυλιστικό νόσημα': 1, '0': 0}
    data['ΝΟΣΗΜΑΤΑ ΠΑΤΡΟΣ - v'] = data['ΝΟΣΗΜΑΤΑ ΠΑΤΡΟΣ - v'].map(npmap)

    remap = {'0': 1, '1': 0}
    data['ΡΥΘΜΟΣ ΣΙΤΙΣΗΣ - v'] = data['ΡΥΘΜΟΣ ΣΙΤΙΣΗΣ - v'].map(remap)

    data_categ = ['ΚΥΗΣΗ - v', 'ΚΑΠΝΙΣΜΑ ΠΡΟ ΚΥΗΣΗΣ - v', 'Σ.Δ. ΚΥΗΣΗΣ - v', 'IUGR (ενδομήτρια καθυστέρηση αύξησης) - v', 'ΚΑΠΝΙΣΜΑ ΚΑΤΑ ΤΗΝ ΚΥΗΣΗ - v', 'ΑΛΛΑ ΠΡΟΒΛΗΜΑΤΑ ΚΑΤΑ ΤΗΝ ΚΥΗΣΗ - v',\
                  'SGA - v', 'ΤΟΚΕΤΟΣ - v', 'ΙΚΤΕΡΟΣ - v', 'ΥΠΟΓΛΥΚΑΙΜΙΑ - v', 'ΠΑΡΑΜΟΝΗ ΣΕ ΜΕΝ / ΜΑΦ - v','ΘΗΛΑΣΜΟΣ - v', 'ΑΛΛΕΡΓΙΕΣ - v',\
                  'ΦΑΡΜΑΚΑ / ΒΙΤΑΜΙΝΕΣ / ΣΥΜΠΛΗΡΩΜΑΤΑ - v', 'Χρόνια νοσήματα - v', 'Συγγενή νοσήματα - v', 'ΝΟΣΗΛΕΙΕΣ - v', 'ΝΟΣΗΜΑΤΑ ΜΗΤΡΟΣ - v', 'ΝΟΣΗΜΑΤΑ ΠΑΤΡΟΣ - v',\
                  'ΑΔΕΛΦΙΑ - v', 'ΜΕΣΟΔΙΑΣΤΗΜΑΤΑ ΜΕΤΑΞΥ ΓΕΥΜΑΤΩΝ: - v', 'ΑΡΙΘΜΟΣ ΜΙΚΡΟΓΕΥΜΑΤΩΝ / ΣΝΑΚ - v',\
                  'Πόσες ώρες περίπου παίζει βιντεοπαιχνίδια  το παιδί σας τις καθημερινές; - v', 'Πόσες ώρες περίπου την ημέρα (Σαββατοκύριακο ή αργίες)  πέρασε το παιδί σας μπροστά σε οθόνες; (π.χ. τηλεόραση, τάμπλετ, κινητό) - v',\
                  'ΠΡΟΣΩΠΑ ΦΡΟΝΤΙΔΑΣ ΣΙΤΙΣΗΣ ΠΑΙΔΙΟΥ: - v', 'Πόσο συχνά τρώει το παιδί σας ψάρια ή θαλασσινά; - v', 'Πόσες ώρες την ημέρα περίπου κοιμάται το παιδί σας (μέσος όρος); - v',\
                  'Πόσες ώρες περίπου παίζει βιντεοπαιχνίδια το παιδί σας τα Σαββατοκύριακα; - v', 'Πόσες φορές την εβδομάδα το παιδί σας είχε δυσκολίες στον ύπνο (π.χ. αϋπνία, δυσκολία στην έναρξη του ύπνου, συχνά ξυπνήματα, τρίξιμο δοντιών); - v',\
                  'Πόσο συχνά χρησιμοποιείτε ελαιόλαδο στο μαγείρεμα; - v', 'Το παιδί μου ζητάει συνεχώς φαγητό - v', 'Πόσο συχνά τρώει το παιδί σας όσπρια; - v',\
                  'Πόσο συχνά χρησιμοποιείτε βούτυρο; - v', 'Ακόμη κι αν έχει χορτάσει, το παιδί μου βρίσκει χώρο για το αγαπημένο του φαγητό - v', 'Πόσο συχνά χρησιμοποιείτε άλλα φυτικά έλαια στο μαγείρεμα; - v',\
                  'Εάν είχε την επιλογή, το παιδί μου θα έτρωγε την περισσότερη ώρα της ημέρας - v', 'Πόσο συχνά τρώει το παιδί σας ξηρούς καρπούς (μια μερίδα αντιστοιχεί σε μια χούφτα ξηρών καρπών (π.χ. 18 αμύγδαλα, 6 ολόκληρα καρύδια, 3 κουταλιές της σούπας ηλιόσπορους)  ή προϊόντα τους  όπως ταχίνι, φυστικοβούτυρο κ.ά. (μια μερίδα αντιστοιχεί σε 1½  κουταλιά της σούπας των 15ml ή 25γρ. π.χ. ταχίνι) - v',\
                  'Πόσο συχνά χρησιμοποιείτε μαργαρίνη; - v', 'Πόσες μερίδες φρούτων καταναλώνει το παιδί σας (μέσος όρος); - v', 'Πόσες μερίδες λαχανικών (ωμών ή βραστών ή στον ατμό ή ψητών) καταναλώνει το παιδί σας (μέσος όρος); - v',\
                  'Πόσες μερίδες γαλακτοκομικών (ένα ποτήρι γάλα των 250ml, ένα κεσεδάκι γιαούρτι των 200γρ, μια φέτα τυρί του τοστ)  καταναλώνει  το παιδί σας (μέσος όρος); - v',\
                  'Πόσες μερίδες δημητριακών καταναλώνει  το παιδί σας (μέσος όρος); - v', 'Από τις παραπάνω  μερίδες δημητριακών που καταναλώνει συνήθως το παιδί σας ημερησίως πόσες περιέχουν δημητριακά ολικής άλεσης όπως τοστ ολικής άλεσης, ψωμί ολικής άλεσης  ή πολύσπορο, παξιμάδια ολικής άλεσης, ζυμαρικά ολικής άλεσης, ποπ κορν, δημητριακά πρωινού με περιεκτικότητα σε φυτικές ίνες > 3γρ / 100γρ προϊόντος: - v',\
                  'Πόσο συχνά  καταναλώνει το παιδί σας λευκό κρέας (κοτόπουλο, γαλοπούλα, πάπια, κουνέλι, κυνήγι); - v', 'Πόσο συχνά  καταναλώνει το παιδί σας κόκκινο κρέας (μοσχάρι, χοιρινό, κατσίκι, αρνί); - v',\
                  'Πόσες φορές την εβδομάδα κατανάλωσε το παιδί σας επεξεργασμένο κρέας (π.χ. μια φέτα ζαμπόν, μια φέτα γαλοπούλα, μια φέτα σαλάμι, μια φέτα παριζάκι , ένα μεσαίο λουκάνικο) - v',\
                  'Το παιδί μου έχει μεγάλη όρεξη - v', 'Πόσο συχνά τρώει το παιδί σας λαδερό φαγητό (π.χ. φασολάκια πράσινα, αρακά, μπριάμ); - v',\
                  'Το παιδί μου ΔΕΝ χορταίνει εύκολα - v', 'Το παιδί μου ΔΕΝ αφήνει φαγητό στο πιάτο στο τέλος του γεύματος - v', 'Πόσο συχνά τρώει το παιδί σας έτοιμο φαγητό ταχυφαγείου (π.χ. πίτα με γύρο, πίτσα); - v',\
                  'Το παιδί μου απορρίπτει νέα φαγητά στην αρχή - v', 'Πόσο συχνά καταναλώνει το παιδί σας αυγά (σε οποιαδήποτε μορφή, βραστά, τηγανητά, ομελέτα, σε συνταγές); - v', 'Το παιδί μου μπορεί να φάει ένα γεύμα αν έχει φάει σνακ λίγο πριν - v',\
                  'Πόσο συχνά πίνει το παιδί σας  αναψυκτικά τύπου coca cola ή fanta (330ml)  ή χυμούς εμπορίου π.χ. αμίτα  (1 ποτήρι των 250 ml); - v', 'Το παιδί μου ΔΕΝ ενδιαφέρεται να δοκιμάσει νέα φαγητά - v',\
                  'Πόσο συχνά τρώει το παιδί σας τυποποιημένα προϊόντα με πολλές θερμίδες (δηλαδή >250kcal ανά 100γρ. προϊόντος) και υψηλά σε απλά σάκχαρα (δηλαδή με σάκχαρα > 22,5γρ. ανά 100γρ προϊόντος) ή υψηλά σε αλάτι (δηλαδή > 1,5γρ. αλατιού ή 0,6γρ νατρίου ανά 100 γρ προϊόντος) (π.χ. 1 σακούλι πατατάκια 70γρ, 1 κρουασάν 100γρ, 1 ντόνατς 100γρ, 1 σοκολάτα 100γρ, ≥ 3 μπισκότα τύπου γεμιστά) - v',\
                  'Το παιδί μου δύσκολα ικανοποιείται με τα γεύματα - v', 'ΟΙΚΟΓΕΝΕΙΑΚΑ ΓΕΥΜΑΤΑ - v', 'Τι είδους άσκηση έκανε το παιδί σας την προηγούμενη βδομάδα; - v', 'ΡΥΘΜΟΣ ΣΙΤΙΣΗΣ - v',\
                  'Πόσα λεπτά την ημέρα περίπου ήταν το παιδί σας σωματικά δραστήριο (περπάτημα, ποδήλατο, πατίνι, παιχνίδια με φίλους που απαιτούν σωματική δραστηριότητα, κηπουρική, μαγειρική, δουλειές σπιτιού) - v',\
                  'Πόσες φορές την εβδομάδα ασκήθηκε (οργανωμένο σπορ) το παιδί σας; - v', 'ΑΡΙΘΜΟΣ ΚΥΡΙΩΝ ΓΕΥΜΑΤΩΝ - v', 'Πόσες ώρες περίπου την ημέρα (καθημερινές)  πέρασε το παιδί σας  μπροστά σε οθόνες; (π.χ. τηλεόραση, τάμπλετ, κινητό) - v',\
                  'Φύλο - v', 'Ηλικία - v', 'Με βάση το ύψος σας και το σωματικό σας βάρος, θεωρείτε πως είστε - v', 'Ποια είναι η οικογενειακή σας κατάσταση; - v',\
                  'Ποια είναι η εθνικότητά σας*; - v', 'Ποιο είναι το μορφωτικό σας επίπεδο; - v',\
                  'Ποια είναι η εργασία σας; (σε περίπτωση συνταξιοδότησης σημειώνετε την απασχόληση πριν από τη συνταξιοδότηση) - v', 'Είστε ικανοποιημένος με το εισόδημά σας; - v',\
                  'Ποιο είναι το ακαθάριστο ετήσιο εισόδημά σας; (η ερώτηση αυτή είναι προαιρετική) - v', 'Είστε καπνιστής; - v', 'Το οικογενειακό σας εισόδημα καλύπτει τις ανάγκες σας; - v',\
                  'Ασκείστε; Πόσο συχνά; - v', 'Καταναλώνετε αλκοολούχα ποτά; - v', 'Νοσείτε από κάποια χρόνια ασθένεια (πχ. Υπέρταση, Δυσλιπιδαιμία, Διαβήτη,); - v', 'Πόσο καλή είναι η υγεία σας; - v']

    #replace with the most frequent value
    for col in data_categ:
      data = data.fillna(data[col].value_counts().index[0])

    #for name,col_type in zip(data.columns,data.dtypes):
        #if ("Score" in name):
          #print (name,col_type)

    """  ## Get Dummies - One hot encoding"""

    dum_catg_ftrs = ['target', 'home', 'junk']

    data = pd.get_dummies(data, columns=dum_catg_ftrs)

    """# Create classes from steps feature"""

    # 0 -5000 steps => Class 0 (No exercise)
    # 5000 - 10000 steps => Class 1 (A little exercise)
    # >=10000 steps => Class 2 (Lots of exercise)

    data.loc[data["steps"] < 5000, "steps"] = 0
    data.loc[((data["steps"] > 5000) & (data["steps"] < 10000)), "steps"] = 1
    data.loc[(data["steps"] >= 10000), "steps"] = 2

    """### Examine correlation between features

    plt.figure(figsize=(20, 8))
    # Store heatmap object in a variable to easily access it when you want to include more features (such as title).
    # Set the range of values to be displayed on the colormap from 0 to 1, and set the annotation to True to display the correlation values on the heatmap.
    heatmap = sns.heatmap(data.corr(), vmin=0, vmax=1, annot=True)
    # Give a title to the heatmap. Pad defines the distance of the title from the top of the heatmap.
    heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);

    ## Check again for missing values
    """

    ##print columns and their missing values after removing them
    # for column in data.columns:
    # print(column,": ",data[column].isnull().sum())

    """### Remove duplicates"""

    # print(data.shape)
    data = data.drop_duplicates()
    # print(data.shape)

    #print(data.columns)

    # NORMALIZATION
    from sklearn import preprocessing
    from sklearn.cluster import KMeans

    for column in data.columns:
        if (column != 'pid') and (column != 'timestamp'):
            data[column].fillna(data[column].mean(), inplace=True)

    data = data.dropna()
    data = data.dropna(axis=0)
    data = data.dropna(subset=['pid', 'timestamp'])
    pids = data['pid']
    dates = data['timestamp']
    data = data.drop('pid', 1)
    data = data.drop('timestamp', 1)

    scaler = preprocessing.StandardScaler().fit(data)
    data = scaler.transform(data)
    n_components = 3

    from sklearn.metrics import silhouette_score

    silhouette_scores = []
    for k in range(2, 20):
        km = KMeans(k, random_state=77)
        km.fit(data)
        preds = km.predict(data)
        silhouette_scores.append(silhouette_score(data, preds))

    max_value = max(silhouette_scores)
    # kbest = silhouette_scores.index(max_value)
    kbest = 3

    km = KMeans(kbest)
    km.fit(data)

    fig = plt.figure(figsize=(10, 7))
    ax = plt.axes(projection="3d")

    # Creating plot
    results = km.predict(data)
    pca = PCA(n_components=n_components)
    pca_data = pca.fit_transform(data)
    ax.scatter3D(pca_data[:, 0], pca_data[:, 1], pca_data[:, 2], c=results)
    results = pd.Series(results)
    plt.title("Clusters (k={}) of joined data".format(kbest))

    # show plot
    plt.show()

    #print(pids)
    #print(pids.isna().sum())
    #print(len(pids),len(dates),len(results))
    final_results = pd.concat([pids, dates, results], axis=1).reset_index()
    final_results = final_results.dropna()
    #print(final_results)
    final_results.to_csv("clustering_results.csv")













